---
title: "Practical Machine Learning Course Project Test"
author: "Doug McCaleb"
date: "Saturday, July 25, 2015"
output: html_document
---

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
summary(cars)
```

You can also embed plots, for example:

```{r, echo=FALSE, }
plot(cars)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

## Executive Summary

In this class project for Practical Machine Learning with Jeff Leek, PhD, of Johns Hopkins Bloomberg School of Public Health, we derive the machine knowledge necessary for the machine to be able to interpret data to infer whether six people performed barbell lifts correctly or incorrectly.  The manner in which the physical exercises are performed is identified in the _classe_ variable, which reflects the category of each outcome alphanumerically as "A", "B", "C", "D", or "E".  

"Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes." "Six young [male] health participants [aged between 20 - 28 years]  were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E)." (See http://groupware.les.inf.puc-rio.br/har#dataset)

Specifically, the goal of this project is to determine, without reference to the _classe_ variable in test data, whether the test participats performed the physical exercises correclty and, if they did not perform the exercises correctly, in what manner they performed them incorrectly.

The data are taken from personal fitness devices such as the FitBit, the Nike FuelBand, and Jawbone Up, all of which are able to produce signficant amounts of data. The data we will use for machine training comes from https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv, and the data for testing the machine's knowledge comes from https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv.  These data are provided by http://groupware.les.inf.puc-rio.br/har.

This document summarizes 1) how the machine knowlege ("the model") was built, 2) how we cross-validated it, 3) what the expected out-of-sample error is, and what choices are made. 

### Housekeeping

```{r LibrariesSeed, echo=TRUE, warning=FALSE, message=FALSE,  }

library(RCurl)
library(caret)
library(rattle)
library(randomForest)
library(rpart.plot)
library(ggplot2)
library(lattice)
set.seed(123)
```

```{r EnableReadCSVURL, echo=FALSE, warning=FALSE, message=FALSE}
# From http://stackoverflow.com/questions/28997402/r-read-csv-from-url-error-in-knitr
# Enables direct read.csv of URL-sourced data from within Knitr execution.

read.csv.orig = read.csv

read.csv = function(file, ...) {
  if (is.character(file)) {
    if (grepl('^https://', file)) {
      data = getURL(file, ssl.verifypeer=0L, followlocation=1L)
      return (read.csv.orig(text=data, ...))  
    } else if (grepl('^http://', file)) {
      data = getURL(file)
      return (read.csv.orig(text=data, ...)) 
    } else {
      return (read.csv.orig(file, ...))
    }
  } else {
    return (read.csv.orig(file, ...))
  }
}
```

### Getting, Exploring, Cleaning, and Structuring the Data

Here we get the data from the sources, setting missing data along the way, and take a look at the structure.

```{r DownloadAndRead, echo=TRUE}
trainingData <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", na.strings=c("NA", "#DIV/0!", ""))
testingData  <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",  na.strings=c("NA", "#DIV/0!", ""))
```

Let's take a look at the data . . .

```{r Structure, echo = TRUE}
str(trainingData, list.len = 10)
str(testingData, list.len = 10)
table(trainingData$classe)
table(testingData$classe)
```

We double-check for missing data . . .

```{r CheckColumnsOfMissingData, echo=TRUE}
ncol(trainingData[, colSums(is.na(trainingData))>19621])
ncol(testingData[, colSums(is.na(testingData))>19621])
```

Looks like our missing data checks at download took care of this.

Some basic cleanup -- Based on our exploratory analysis, we will remove columns one through seven due to lack of relevance, and then remove columns that are NA.

```{r RemoveColumns,echo=TRUE}
trainingData <- trainingData[,8:160]
testingData  <- testingData[,8:160]
trainingData <- trainingData[, colSums(is.na(trainingData))==0]
testingData  <- testingData[, colSums(is.na(testingData))==0]
nrow(trainingData[, colSums(is.na(trainingData))>0])
nrow(testingData[, colSums(is.na(testingData))>0])
```

## How We Will Cross-Validate

We break up the training data for cross-validation purposes -- We divide the training data 70% for buidling the model (training), and 30% for testing the model on the training data before applying the model to downloaded test data.  

```{r SplitTrainingData, echo = TRUE}
dataForTraining <- createDataPartition(y = trainingData$classe, p = 0.7, list = FALSE)
trainingTrainingData <- trainingData[dataForTraining,]
testingTrainingData  <- trainingData[-dataForTraining,]
dim(trainingTrainingData)
dim(testingTrainingData)
```

This gives us a set of training data for actual training purposes having 11776 observations, or about 60% of the total training data, in a traingTrainingData.  We also have 7846 observations of training data, in testTrainingData, that we will use to trest our model before final application on the downloaded test data that is in testingData.  

Later, we will use K-fold cross-validation in the random forest alghorithm from the caret package to infer our model in the trainingTrainingData data set.

Before we start on the model, let's check on covariates between trainingTrainingData and testingTrainingData to see if we can further simplify our data by eliminating "zero covariates" that will not help us predict.

```{r NetZeroCovariates, echo = TRUE}
NetZeroCovariateColumns <- nearZeroVar(trainingTrainingData)

NetZeroCovariateColumns
```

We can see from the fact that NetZeroCovariateColumns is zero that our prior data cleaning eliminated net zero covariates and that we should have clean predictors. 

## How the Machine Knowlege ("The Model") is Built

We will first build the model on the training portion of the training data using the randomForest alghorith and evaluate its accuracy and out-of-sample error.


```{r BuildModel, echo = TRUE}
trainingControl <- trainControl(method = "cv", 5)

modelFit <- train(classe ~ ., 
                  data = trainingTrainingData, 
                  method = "rf", 
                  trControl = trainingControl, 
                  ntree = 501)
modelFit
```

## Model Evaluation and Predicting Out-of-Sample Error Rate

We evaluate the model against the testingTrainingData data set first, producing a confusion matrix.

```{r EvaluateModel, echo = TRUE}
testingTrainingDataPredictions <- predict(modelFit, testingTrainingData)

confusionMatrix(testingTrainingData$classe, testingTrainingDataPredictions)
```

The matrix predicts that the accuracy of the model will be 99.17%.

The matrix predicts that the out-of-sample error rate will be .83%.

## Model Application to Test Data

Now we apply our model to the downloaded test data in the testingData data set.

```{r Results, echo = TRUE}

results <- predict(modelFit, testingData)

results
```

## Uploading Results to Coursera

```{r UploadToCoursera, echo = TRUE}
workingDirectory <- getwd()

setwd("F:/Prebuild Keep/Training/Coursera/8. Practical Machine Learning/CourseraSubmissionFiles")

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(results)

setwd(workingDirectory)
```

## References

http://groupware.les.inf.puc-rio.br/har#dataset

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013. 
Read more: http://groupware.les.inf.puc-rio.br/har#dataset#ixzz3gwqpfrXI


